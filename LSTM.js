
class MyLSTM
{
	constructor()
	{
		//a toy LSTM to predict the next token in a string generated by [Reber Grammar](http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/reberGrammar.php)
		//fails on BTSSXXTTTTTTTTTTTTTTTTTTTTTTTTTTTTSXVVE because filter[1] is not quiiiiiite zero.
	}
	
	getReberString(len)
	{
		const tokens  = "BTSXPVE"; 
		let input   = [1,0,0,0,0,0,0]; //current token [B,T,S,X,P,V,E]
		let memory  = [1,0,0,0,0,0];   //one-hot TANH vector of current node in graph
		let eraser  = [0,0,0,0,0,0];   //what to erase in memory
		let writer  = [0,0,0,0,0,0];   //what to write to memory
		let filter  = [1,1,1,1,1,1];   //filter the writer when it returns multiple write values
		let reader  = [0,0,0,0,0,0,0]; //predicted tokens [B,T,S,X,P,V,E]
		
		let str = 'B';
		let safety = 0;
		let debug = false;

		while(str.length < len && safety < 100)
		{
			safety++; 
			
			//memory accumulates evidence of a node being reached (sum of precedent edges)
			//writer adds evidence to memory when precedent edges are crossed
			//filter weeds out false positives in the writer
			//eraser resets memory when required
			//there are many many solutions in weight-space, this is just one of them
			
			let B = input[0];
			let T = input[1];
			let S = input[2];
			let X = input[3];
			let P = input[4];
			let V = input[5];
			let E = input[6];
			
			//B
			eraser[0] = 0;                                                  //always erase
			writer[0] = Math.tanh(5 * B);                                   //increment on B, else do nothing 
			filter[0] = 1;
			
			//T
			eraser[1] = 1 / (1 + exp(-10 * (0.5 - X)));                     //reset on X
			writer[1] = Math.tanh(5 * T);                                   //breadcrumbs to node 1
			filter[1] = 1 / (1 + exp(-30 * (0.75 - memory[5])));            //do not increment from node 5

			//P_P, TX, X_P
			eraser[2] = 1 / (1 + exp(-30 * (0.65 - memory[2])));            //reset on exit
			writer[2] = Math.tanh(0.55 * (T + X + P));                      //breadcrumbs to node 2
			filter[2] = 1 / (1 + exp(-30 * (0.65 - memory[5])));            //do not increment from node 5

			//BP, XX, PX but not BX
			eraser[5] = 1 / (1 + exp(-10 * (0.5 - V)));                     //reset on V
			writer[5] = Math.tanh(0.55 * B + 0.7 * P + 5 * X);              //breadcrumbs to node 5
			filter[5] = 1 / (1 + exp(-30 * (0.65 - memory[1])));            //do not increment from node 1

			//V
			eraser[4] = 1 / (1 + exp(-10 * (0.6 - memory[4])));             //reset on exit
			writer[4] = Math.tanh(5 * V);                                   //breadcrumbs to node 4
			filter[4] = 1 / (1 + exp(-10 * (0.6 - memory[4])));             //filter V on exit

			//S (filter node 1) or VV
			eraser[3] = 1 / (1 + exp(-10 * (0.5 - P)));                     //reset on P
			writer[3] = Math.tanh(3.0 * S + 0.55 * V);                      //breadcrumbs to node 3
			filter[3] = 1 / (1 + exp(-10 * (0.7 - memory[1])));             //do not increment from node 1

			if(debug)
			{
				console.log(str);
				console.log("[B,T,S,X,P,V,E]");
				console.log("input:____" + input.map( e => round(e,2)).join());
				console.log("memory 1:_" + memory.map(e => round(e,2)).join());
				console.log("eraser:___" + eraser.map(e => round(e,2)).join());
				console.log("writer:___" + writer.map(e => round(e,2)).join());
				console.log("filter:___" + filter.map(e => round(e,2)).join());
			}
			
			for(let i = 0; i < memory.length; i++) 
			{ 
				memory[i] = memory[i] * eraser[i] + writer[i] * filter[i]; 
			}

			//|thresholds |false        |true |
			//|---        |---          |---  |
			//| memory[0] | 0.0         | 1.0 |
			//| memory[1] | 0.2         | 1.0 |
			//| memory[2] | 0.5         | 1.0 |
			//| memory[3] | 0.5         | 1.0 |
			//| memory[4] | 0.2         | 1.0 |
			//| memory[5] | 0.4,0.5,0.6 | 1.0 |
			//| memory[6] | 0.0         | 1.0 |
			
			reader[0] = 0; //we never yield B
			reader[1] = Math.tanh(5  * (memory[0] + memory[5] - 0.7)); //T may yield from 0 or 5
			reader[2] = Math.tanh(5  * (memory[1] + memory[2] - 0.7)); //S may yield from 1 or 2
			reader[3] = Math.tanh(5  * (memory[1] + memory[2] - 0.7)); //X may yield from 1 or 2
			reader[4] = Math.tanh(5  * (memory[0] + memory[4] - 0.7)); //P may yield from 0 or 4 
			reader[5] = Math.tanh(5  * (memory[4] + memory[5] - 0.7)); //V may yield from 4 or 5
			reader[6] = Math.tanh(5  * (memory[3]             - 0.7)); //E may yield from 3

			//no read filter layer, not required.
			
			let c = reader
				.map((e, i) => [e, i]) 		
				.filter(e => e[0] > 0.5) 	
				.map(e => e[1]); 					
			;
			if(c.length == 0) console.log("error error error");
			let newToken = random(c);
			
			//append token to string
			str += tokens[newToken]; 
			
			if(debug) 
			{
				console.log("memory 2: " + memory.map(e => round(e,2)).join()); //round(1E-8) returns NaN in p5
				console.log("reader:   " + reader.map(e => round(e,2)).join());
				console.log(str);
				console.log("------");
			}
			
			//graph exit condition
			if(newToken == 6) break; 
			
			//set next input
			input = [0,0,0,0,0,0,0];
			input[newToken] = 1;
			
		}

		if(!reberGrammar.validateString(str, len))
		{
			str += " (grammar violation)";
		}
		else str += "  âœ“";
		
		return str;
	}
}